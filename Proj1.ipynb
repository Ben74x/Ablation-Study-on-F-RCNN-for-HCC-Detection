{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb32a80-0e1b-4ddf-b2ff-1fe20611345b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e496b5c5-b8f1-40b3-821c-ed62af8f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import neptune\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from pytorch_faster_rcnn.datasets import ObjectDetectionDatasetSingle, ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn.faster_RCNN import get_faster_rcnn_resnet\n",
    "from pytorch_faster_rcnn.transformations import ComposeDouble\n",
    "from pytorch_faster_rcnn.transformations import ComposeSingle\n",
    "from pytorch_faster_rcnn.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn.transformations import FunctionWrapperSingle\n",
    "from pytorch_faster_rcnn.transformations import apply_nms, apply_score_threshold\n",
    "from pytorch_faster_rcnn.transformations import normalize_01\n",
    "from pytorch_faster_rcnn.utils import get_filenames_of_path, collate_single, save_json\n",
    "from pytorch_faster_rcnn.visual import DatasetViewer\n",
    "from pytorch_faster_rcnn.visual import DatasetViewerSingle\n",
    "from pytorch_faster_rcnn.backbone_resnet import ResNetBackbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c67719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f582ef-cf8b-4ddd-bfce-e986bfa6a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {'EXPERIMENT': 'IN-58',  # experiment name, \n",
    "          'OWNER': 'bdwumah',  # e.g. johndoe55\n",
    "          'INPUT_DIR': 'C:/Users/adcm108/Indiv_Proj-main/tests/images',  # files to predict\n",
    "          'PREDICTIONS_PATH': 'predictions',  # where to save the predictions\n",
    "          'MODEL_DIR': 'C:/Users/adcm108/Indiv_Proj-main/.neptune/Untitled/IN-58/checkpoints/',  # load model from checkpoint\n",
    "          'DOWNLOAD': False,  # whether to download from neptune\n",
    "          'DOWNLOAD_PATH': 'model',  # where to save the model if DOWNLOAD is True\n",
    "          'PROJECT': 'Individual-Project-1',  # Project name\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f8bab4-464b-480b-883e-3e8e5e267ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "inputs = get_filenames_of_path(pathlib.Path(params['INPUT_DIR']))\n",
    "inputs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c30ad2-9fd9-4090-b300-78a36fe83ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "transforms = ComposeSingle([\n",
    "    FunctionWrapperSingle(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperSingle(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f296e5-971c-40bc-a7ae-cdb3f110ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = ObjectDetectionDatasetSingle(inputs=inputs,\n",
    "                                       transform=transforms,\n",
    "                                       use_cache=False,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e02b562-62e3-42a1-abbd-892c3b77f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataloader_prediction = DataLoader(dataset=dataset,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=0,\n",
    "                                   collate_fn=collate_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ca9ab1-70c3-4d8c-895c-780e5b159120",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4MjEwNWM2NC1jNmM5LTQyYTctOGRlNy1hN2M0YTk2MmY0N2QifQ=='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8857b5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bdwumah/Individual-Project-1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}'\n",
    "project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e122a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4MjEwNWM2NC1jNmM5LTQyYTctOGRlNy1hN2M0YTk2MmY0N2QifQ=='"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618796d3-1009-42ce-8fbc-4e8197a652ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import experiment from neptune\n",
    "project_name = f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}'\n",
    "project = neptune.init(project_qualified_name=project_name, api_token=api_key)  # get project\n",
    "experiment_id = params['EXPERIMENT']  # experiment id\n",
    "experiment = project.get_experiments(id=experiment_id)[0]\n",
    "#properties = experiment.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa20fd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f455a449-db53-4e14-aa41-e2192ce719a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcnn transform\n",
    "transform = GeneralizedRCNNTransform(min_size=1024,\n",
    "                                     max_size=1024,\n",
    "                                     image_mean=ast.literal_eval('[0.485, 0.456, 0.406]'),\n",
    "                                     image_std=ast.literal_eval('[0.229, 0.224, 0.225]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abcea34a-aeb6-4ca2-9208-ac71074819b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dataset\n",
    "datasetviewer = DatasetViewerSingle(dataset, rccn_transform=None)\n",
    "datasetviewer.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8277d891-0926-4005-938f-a8caf9646ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/adcm108/Indiv_Proj-main/.neptune/Untitled/IN-58/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     model_state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(download_path \u001b[38;5;241m/\u001b[39m model_name, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMODEL_DIR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     model_state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/adcm108/Indiv_Proj-main/.neptune/Untitled/IN-58/checkpoints'"
     ]
    }
   ],
   "source": [
    "# download model from neptune or load from checkpoint\n",
    "if params['DOWNLOAD']:\n",
    "    download_path = pathlib.Path(os.getcwd()) / params['DOWNLOAD_PATH']\n",
    "    download_path.mkdir(parents=True, exist_ok=True)\n",
    "    model_name = 'best_model.pt'  # that's how I called the best model\n",
    "    # model_name = properties['checkpoint_name']  # logged when called log_model_neptune()\n",
    "    if not (download_path / model_name).is_file():\n",
    "        experiment.download_artifact(path=model_name, destination_dir=download_path)  # download model\n",
    "\n",
    "    model_state_dict = torch.load(download_path / model_name, map_location=torch.device('cpu'))\n",
    "else:\n",
    "    checkpoint = torch.load(params['MODEL_DIR'], map_location=torch.device('cpu'))\n",
    "    model_state_dict = checkpoint['hyper_parameters']['model'].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a78b32-2283-45ad-83c2-11337e4c2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_faster_rcnn_resnet(num_classes=int(parameters['CLASSES']),\n",
    "                               backbone_name=ResNetBackbones(parameters['BACKBONE']),  # reverse look-up enum\n",
    "                               anchor_size=ast.literal_eval(parameters['ANCHOR_SIZE']),\n",
    "                               aspect_ratios=ast.literal_eval(parameters['ASPECT_RATIOS']),\n",
    "                               fpn=ast.literal_eval(parameters['FPN']),\n",
    "                               min_size=int(parameters['MIN_SIZE']),\n",
    "                               max_size=int(parameters['MAX_SIZE'])\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d659f25-0d7d-4a97-be15-5795e24f2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59d69e-b9ca-45b3-8320-2a7d4a0e4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference (cpu)\n",
    "model.eval()\n",
    "for sample in dataloader_prediction:\n",
    "    x, x_name = sample\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = {key: value.numpy() for key, value in pred[0].items()}\n",
    "        name = pathlib.Path(x_name[0])\n",
    "        save_dir = pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH']\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pred_list = {key: value.tolist() for key, value in pred.items()}  # numpy arrays are not serializable -> .tolist()\n",
    "        save_json(pred_list, path=save_dir / name.with_suffix('.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e424-4308-4586-a2ca-d0349cffc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction files\n",
    "predictions = get_filenames_of_path(pathlib.Path(os.getcwd()) / params['PREDICTIONS_PATH'])\n",
    "predictions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66697a0b-7989-4e44-8056-b62b70a49bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataset\n",
    "iou_threshold = 0.25\n",
    "score_threshold = 0.6\n",
    "\n",
    "transforms_prediction = ComposeDouble([\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01),\n",
    "    FunctionWrapperDouble(apply_nms, input=False, target=True, iou_threshold=iou_threshold),\n",
    "    FunctionWrapperDouble(apply_score_threshold, input=False, target=True, score_threshold=score_threshold)\n",
    "])\n",
    "\n",
    "dataset_prediction = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                            targets=predictions,\n",
    "                                            transform=transforms_prediction,\n",
    "                                            use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb62e53-0e06-4bb5-86a3-8c23d1556ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "color_mapping = {\n",
    "    1: 'red',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50e474-202d-48ac-b5d0-13d69c3b7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "datasetviewer_prediction = DatasetViewer(dataset_prediction, color_mapping)\n",
    "datasetviewer_prediction.napari()\n",
    "# add text properties gui\n",
    "datasetviewer_prediction.gui_text_properties(datasetviewer_prediction.shape_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b26ebc-1df1-4829-9e72-1bd2452976e7",
   "metadata": {},
   "source": [
    "## Experiment with Non-maximum suppression (nms) and score-thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b440cbf-94fa-439c-ac9f-134959617f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with nms and score-thresholding\n",
    "transforms_prediction = ComposeDouble([\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])\n",
    "\n",
    "dataset_prediction = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                            targets=predictions,\n",
    "                                            transform=transforms_prediction,\n",
    "                                            use_cache=False)\n",
    "\n",
    "color_mapping = {\n",
    "    1: 'red',\n",
    "}\n",
    "\n",
    "datasetviewer_prediction = DatasetViewer(dataset_prediction, color_mapping)\n",
    "datasetviewer_prediction.napari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde50455-2b3b-4530-bf12-fbade6e19bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add score slider\n",
    "# DOES CURRENTLY NOT WORK\n",
    "# datasetviewer_prediction.gui_score_slider(datasetviewer_prediction.shape_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace35a64-c53d-40f5-941e-485e085746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nms slider\n",
    "# DOES CURRENTLY NOT WORK\n",
    "# datasetviewer_prediction.gui_nms_slider(datasetviewer_prediction.shape_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

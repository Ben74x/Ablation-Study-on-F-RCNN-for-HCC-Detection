{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37311f1e",
   "metadata": {},
   "source": [
    "## Faster R-CNN Implementation\n",
    "This notebook is a direct implementation of [johschmidt42's](https://github.com/johschmidt42/PyTorch-Object-Detection-Faster-RCNN-Tutorial/blob/master/training_script.ipynb) Faster RCNN tutorial on github with modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c27595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import pathlib\n",
    "from utils import get_filenames_of_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a48cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "from pytorch_faster_rcnn.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn.transformations import Clip, ComposeDouble\n",
    "from pytorch_faster_rcnn.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn.transformations import normalize_01\n",
    "from pytorch_faster_rcnn.utils import get_filenames_of_path\n",
    "from pytorch_faster_rcnn.utils import stats_dataset\n",
    "from pytorch_faster_rcnn.visual import DatasetViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdd373",
   "metadata": {},
   "source": [
    "## Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "191d935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/adcm108/Indiv_Proj-main')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root directory\n",
    "root = pathlib.Path.cwd()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abdea2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root /'Dataset'/'input')\n",
    "targets = get_filenames_of_path(root / 'Dataset'/'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12240c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "mapping = {\n",
    "    'HCC': 1,\n",
    "    'Non-HCC': 2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40595215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "transforms = ComposeDouble([\n",
    "    Clip(),\n",
    "    # AlbumentationWrapper(albumentation=A.HorizontalFlip(p=0.5)),\n",
    "    # AlbumentationWrapper(albumentation=A.RandomScale(p=0.5, scale_limit=0.5)),\n",
    "    # AlbumentationWrapper(albumentation=A.VerticalFlip(p=0.5)),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dd1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset building\n",
    "dataset = ObjectDetectionDataSet(inputs=inputs,\n",
    "                                 targets=targets,\n",
    "                                 transform=transforms,\n",
    "                                 use_cache=False,\n",
    "                                 convert_to_format=None,\n",
    "                                 mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522d34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_height': tensor([768., 768., 768.,  ..., 576., 576., 576.]),\n",
       " 'image_width': tensor([1024., 1024., 1024.,  ..., 1024., 1024., 1024.]),\n",
       " 'image_mean': tensor([-1.5360, -1.5360, -1.5360,  ..., -1.5607, -1.5607, -1.5607]),\n",
       " 'image_std': tensor([0.7493, 0.7493, 0.7493,  ..., 0.8854, 0.8854, 0.8854]),\n",
       " 'boxes_height': tensor([144.0000, 144.0000, 144.0000,  ...,  40.0000,  40.0000,  40.0000]),\n",
       " 'boxes_width': tensor([140.8000, 140.8000, 140.8000,  ...,  34.4000,  34.4000,  34.4000]),\n",
       " 'boxes_num': tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       " 'boxes_area': tensor([20275.1934, 20275.1934, 20275.1934,  ...,  1376.0009,  1376.0009,\n",
       "          1376.0009])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = GeneralizedRCNNTransform(min_size=1024,\n",
    "                                     max_size=1024,\n",
    "                                     image_mean=[0.485, 0.456, 0.406],\n",
    "                                     image_std=[0.229, 0.224, 0.225])\n",
    "\n",
    "stats_transform = stats_dataset(dataset, transform)\n",
    "stats_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a670e1",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e655223d-57bd-47e7-9da6-bd6a04ff4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from utils import from_dict_to_boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b12d81-d304-4061-904c-df3b394badc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterRCNN_lightning(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 lr: float = 0.0001,\n",
    "                 iou_threshold: float = 0.5\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Model\n",
    "        self.model = model\n",
    "\n",
    "        # Classes (background inclusive)\n",
    "        self.num_classes = self.model.num_classes\n",
    "\n",
    "        # Learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # IoU threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "\n",
    "        # Transformation parameters\n",
    "        self.mean = model.image_mean\n",
    "        self.std = model.image_std\n",
    "        self.min_size = model.min_size\n",
    "        self.max_size = model.max_size\n",
    "\n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model.eval()\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Batch\n",
    "        x, y, x_name, y_name = batch  # tuple unpacking\n",
    "\n",
    "        loss_dict = self.model(x, y)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        self.log_dict(loss_dict)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Batch\n",
    "        x, y, x_name, y_name = batch\n",
    "\n",
    "        # Inference\n",
    "        preds = self.model(x)\n",
    "\n",
    "        gt_boxes = [from_dict_to_BoundingBox(target, name=name, groundtruth=True) for target, name in zip(y, x_name)]\n",
    "        gt_boxes = list(chain(*gt_boxes))\n",
    "\n",
    "        pred_boxes = [from_dict_to_BoundingBox(pred, name=name, groundtruth=False) for pred, name in zip(preds, x_name)]\n",
    "        pred_boxes = list(chain(*pred_boxes))\n",
    "\n",
    "        return {'pred_boxes': pred_boxes, 'gt_boxes': gt_boxes}\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        gt_boxes = [out['gt_boxes'] for out in outs]\n",
    "        gt_boxes = list(chain(*gt_boxes))\n",
    "        pred_boxes = [out['pred_boxes'] for out in outs]\n",
    "        pred_boxes = list(chain(*pred_boxes))\n",
    "\n",
    "        from metrics.pascal_voc_evaluator import get_pascalvoc_metrics\n",
    "        from metrics.enumerators import MethodAveragePrecision\n",
    "        metric = get_pascalvoc_metrics(gt_boxes=gt_boxes,\n",
    "                                       det_boxes=pred_boxes,\n",
    "                                       iou_threshold=self.iou_threshold,\n",
    "                                       method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION,\n",
    "                                       generate_table=True)\n",
    "\n",
    "        per_class, mAP = metric['per_class'], metric['mAP']\n",
    "        self.log('Validation_mAP', mAP)\n",
    "\n",
    "        for key, value in per_class.items():\n",
    "            self.log(f'Validation_AP_{key}', value['AP'])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Batch\n",
    "        x, y, x_name, y_name = batch\n",
    "\n",
    "        # Inference\n",
    "        preds = self.model(x)\n",
    "\n",
    "        gt_boxes = [from_dict_to_BoundingBox(target, name=name, groundtruth=True) for target, name in zip(y, x_name)]\n",
    "        gt_boxes = list(chain(*gt_boxes))\n",
    "\n",
    "        pred_boxes = [from_dict_to_BoundingBox(pred, name=name, groundtruth=False) for pred, name in zip(preds, x_name)]\n",
    "        pred_boxes = list(chain(*pred_boxes))\n",
    "\n",
    "        return {'pred_boxes': pred_boxes, 'gt_boxes': gt_boxes}\n",
    "\n",
    "    def test_epoch_end(self, outs):\n",
    "        gt_boxes = [out['gt_boxes'] for out in outs]\n",
    "        gt_boxes = list(chain(*gt_boxes))\n",
    "        pred_boxes = [out['pred_boxes'] for out in outs]\n",
    "        pred_boxes = list(chain(*pred_boxes))\n",
    "\n",
    "        from metrics.pascal_voc_evaluator import get_pascalvoc_metrics\n",
    "        from metrics.enumerators import MethodAveragePrecision\n",
    "        metric = get_pascalvoc_metrics(gt_boxes=gt_boxes,\n",
    "                                       det_boxes=pred_boxes,\n",
    "                                       iou_threshold=self.iou_threshold,\n",
    "                                       method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION,\n",
    "                                       generate_table=True)\n",
    "\n",
    "        per_class, mAP = metric['per_class'], metric['mAP']\n",
    "        self.log('Test_mAP', mAP)\n",
    "\n",
    "        for key, value in per_class.items():\n",
    "            self.log(f'Test_AP_{key}', value['AP'])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                    lr=self.lr,\n",
    "                                    momentum=0.9,\n",
    "                                    weight_decay=0.005)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  mode='max',\n",
    "                                                                  factor=0.75,\n",
    "                                                                  patience=30,\n",
    "                                                                  min_lr=0)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler, 'monitor': 'Validation_mAP'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e486f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a3e4af-d935-4eb9-adc9-d52e8962d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pathlib\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import albumentations as albu\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ff662d-8770-4cd3-b697-11c3b642d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_faster_rcnn.backbone_resnet import ResNetBackbones\n",
    "from pytorch_faster_rcnn.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn.faster_RCNN import (\n",
    "    FasterRCNNLightning,\n",
    "    get_faster_rcnn_resnet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c81633-aa21-40e5-8411-4c97c91a92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_faster_rcnn.transformations import (\n",
    "    AlbumentationWrapper,\n",
    "    Clip,\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    normalize_01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cffca3b-9bca-4c43-9222-b30d2d08ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_faster_rcnn.utils import (\n",
    "    collate_double,\n",
    "    get_filenames_of_path,\n",
    "    log_mapping_neptune,\n",
    "    log_model_neptune,\n",
    "    log_packages_neptune,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17dc978e-a7f3-4c55-b673-b2ccc5aa6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "@dataclass\n",
    "class Params:\n",
    "    BATCH_SIZE: int = 2\n",
    "    OWNER: str = \"bdwumah\"  # set your name here, e.g. johndoe22\n",
    "    LOG_MODEL: bool = False  # whether to log the model to neptune after training\n",
    "    GPU: Optional[int] = 1  # set to None for cpu training / 1 for GPU training\n",
    "    LR: float = 0.001\n",
    "    PRECISION: int = 32\n",
    "    CLASSES: int = 3\n",
    "    SEED: int = 42\n",
    "    PROJECT: str = \"bdwumah/Individual-Project-1\"\n",
    "    EXPERIMENT: str = \"Resnet-18\"\n",
    "    MAXEPOCHS: int = 150\n",
    "    PATIENCE: int = 50\n",
    "    BACKBONE: ResNetBackbones = ResNetBackbones.RESNET152\n",
    "    FPN: bool = True\n",
    "    ANCHOR_SIZE: Tuple[Tuple[int, ...], ...] = ((32,), (64,), (128,), (256,)) \n",
    "    ASPECT_RATIOS: Tuple[Tuple[float, ...]] = ((0.5, 1.0, 2.0),)\n",
    "    MIN_SIZE: int = 1024\n",
    "    MAX_SIZE: int = 1024\n",
    "    IMG_MEAN: List = field(default_factory=lambda: [0.485, 0.456, 0.406])\n",
    "    IMG_STD: List = field(default_factory=lambda: [0.229, 0.224, 0.225])\n",
    "    IOU_THRESHOLD: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71081ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "    IMG_MEAN: List = field(default_factory=lambda: [0.485, 0.456, 0.406])\n",
    "    IMG_STD: List = field(default_factory=lambda: [0.229, 0.224, 0.225])\n",
    "    IOU_THRESHOLD: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e339898-4d29-418e-8bcb-01d9be17da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "ROOT_PATH = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc641b95-b558-4dd5-9432-29651051a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ccf2d03-08d8-4691-9572-775e7efe240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory\n",
    "#save_dir = os.getcwd() if not params.SAVE_DIR else params.SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51aeeaaa-c2e2-4614-aa58-53da41e0beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = ROOT_PATH / 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03cb815a-5b5f-437a-84fc-f17e4f066787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'input')\n",
    "targets = get_filenames_of_path(root / 'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "466b0b10-c496-4a68-b79e-1fe75645b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "        Clip(),\n",
    "        AlbumentationWrapper(albumentation=albu.HorizontalFlip(p=0.5)),\n",
    "        AlbumentationWrapper(\n",
    "            albumentation=albu.RandomScale(p=0.5, scale_limit=0.5)\n",
    "        ),\n",
    "        # AlbuWrapper(albu=A.VerticalFlip(p=0.5)),\n",
    "        FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "        FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c473262-df7a-4596-8325-d122dc6c0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3df3f7d-7a0f-4832-83e0-0cbdff0dbe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transformations\n",
    "transforms_test = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2fbcdb1-bca5-426e-8c66-618569d3a36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random seed\n",
    "seed_everything(params.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a9b86f1-ba12-47a5-9c4a-01a3576e8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training validation test split\n",
    "inputs_train, inputs_valid, inputs_test = inputs[:1000], inputs[1000:1018], inputs[1018:]\n",
    "targets_train, targets_valid, targets_test = targets[:1000], targets[1000:1018], targets[1018:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02aa95fe-271e-4ef6-90e5-8f8e4cfabbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset training\n",
    "dataset_train = ObjectDetectionDataSet(inputs=inputs_train,\n",
    "                                       targets=targets_train,\n",
    "                                       transform=transforms_training,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10b8bba4-fe75-4131-8fbc-9794f1dc5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset validation\n",
    "dataset_valid = ObjectDetectionDataSet(inputs=inputs_valid,\n",
    "                                       targets=targets_valid,\n",
    "                                       transform=transforms_validation,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1153065b-314b-4728-a122-6932bc952f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset test\n",
    "dataset_test = ObjectDetectionDataSet(inputs=inputs_test,\n",
    "                                      targets=targets_test,\n",
    "                                      transform=transforms_test,\n",
    "                                      use_cache=True,\n",
    "                                      convert_to_format=None,\n",
    "                                      mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8ab2f67-34bb-4e43-a7e3-cf1acbb07324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader training\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=params.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_double,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "341a03ff-2bdc-4289-a459-898348c8acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader validation\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c078da2-bbca-4596-a3b3-42b364703848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader test\n",
    "dataloader_test = DataLoader(dataset=dataset_test,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e79f7aff-647b-4089-963e-c3964a885055",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4MjEwNWM2NC1jNmM5LTQyYTctOGRlNy1hN2M0YTk2MmY0N2QifQ==\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "692a92bf-0c0b-400c-b99b-2b679fe5b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/bdwumah/Individual-Project-1/e/IN-81\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "#from neptunecontrib.monitoring.pytorch_lightning import NeptuneLogger\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"bdwumah/Individual-Project-1\",\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4MjEwNWM2NC1jNmM5LTQyYTctOGRlNy1hN2M0YTk2MmY0N2QifQ==\",\n",
    "    log_model_checkpoints=False,\n",
    ")\n",
    "\n",
    "neptune_logger.log_hyperparams(params=params.__dict__)\n",
    "\n",
    "assert neptune_logger.name  # http GET request to check if the project exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e740f-062a-438d-8d68-7e39e3fe5eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a49eded0-2c6e-4f00-b60a-3fe3b81a6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_faster_rcnn_resnet(\n",
    "    num_classes=params.CLASSES,\n",
    "    backbone_name=params.BACKBONE,\n",
    "    anchor_size=params.ANCHOR_SIZE,\n",
    "    aspect_ratios=params.ASPECT_RATIOS,\n",
    "    fpn=params.FPN,\n",
    "    min_size=params.MIN_SIZE,\n",
    "    max_size=params.MAX_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0c5bc92-7911-4d61-a5da-49dffef69429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning init\n",
    "task = FasterRCNNLightning(\n",
    "    model=model, lr=params.LR, iou_threshold=params.IOU_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99d64c49-49f2-4aa8-b5c6-8461b82b3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"Validation_mAP\", mode=\"max\")\n",
    "learningrate_callback = LearningRateMonitor(\n",
    "    logging_interval=\"step\", log_momentum=False\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"Validation_mAP\", patience=params.PATIENCE, mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f192128-1671-4e65-916b-4355ee8e9e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# trainer init\n",
    "trainer = Trainer(\n",
    "    accelerator = 'gpu',\n",
    "    devices=params.GPU,\n",
    "    precision=params.PRECISION,  # try 16 with enable_pl_optimizer=False\n",
    "    callbacks=[checkpoint_callback, learningrate_callback, early_stopping_callback],\n",
    "    #default_root_dir=save_dir,  # where checkpoints are saved to\n",
    "    logger=neptune_logger,\n",
    "    log_every_n_steps=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    max_epochs=params.MAXEPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "722233a9-aefe-40ca-8407-cc04e48ae080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | FasterRCNN | 75.8 M\n",
      "-------------------------------------\n",
      "75.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.8 M    Total params\n",
      "303.367   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d25d181c164fcc84d7850c2215c184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training\n",
    "trainer.fit(\n",
    "    model=task, train_dataloaders=dataloader_train, val_dataloaders=dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d12608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start testing\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67689966-3e56-46ea-8493-e1fda7c554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log model\n",
    "if params.LOG_MODEL:\n",
    "    checkpoint_path = pathlib.Path(checkpoint_callback.best_model_path)\n",
    "    log_model_neptune(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        save_directory=pathlib.Path.home(),\n",
    "        name=\"best_model.pt\",\n",
    "        neptune_logger=neptune_logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f8a97-4f9f-4a40-adeb-c768b8700f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop logger\n",
    "neptune_logger.experiment.stop()\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
